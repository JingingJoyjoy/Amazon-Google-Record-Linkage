{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_train = pd.read_csv(\"preprocessed_amazon_train.csv\", delimiter = \",\")\n",
    "google_train = pd.read_csv(\"preprocessed_google_train.csv\", delimiter = \",\")\n",
    "amazon_test = pd.read_csv(\"preprocessed_amazon_test.csv\", delimiter = \",\")\n",
    "google_test = pd.read_csv(\"preprocessed_google_test.csv\", delimiter = \",\")\n",
    "train_perfect_matching = pd.read_csv(\"preprocessed_train_perfect_matching.csv\", delimiter = \",\")\n",
    "test_perfect_matching = pd.read_csv(\"preprocessed_test_perfect_matching.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r\"\\w+\")\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "\n",
    "def cosine_similarity(str1, str2):\n",
    "    vec1 = text_to_vector(str1)\n",
    "    vec2 = text_to_vector(str2)\n",
    "    cosine_similarity = get_cosine(vec1, vec2)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the distance matrix\n",
    "def similarity_matrix_generator(amazon_key,google_key):\n",
    "    similarity_matrix = np.zeros((len(amazon_key),len(google_key)))\n",
    "    for i in range(0,len(amazon_key)):\n",
    "        for j in range(0,len(google_key)):\n",
    "            similarity_matrix[i][j] = cosine_similarity(amazon_key[i],google_key[j])\n",
    "    return similarity_matrix\n",
    "\n",
    "# Get the potential candidate\n",
    "def potential_matching(amazon_data,google_data,similarity_matrix,threshold):\n",
    "    candidate_index = np.where(similarity_matrix >threshold)\n",
    "    # retrieve index for each set\n",
    "    amazon_index = candidate_index[0]\n",
    "    google_index = candidate_index[1]\n",
    "    print(\"length of amazon index: \"+str(len(amazon_index)))\n",
    "    print(\"length of google index: \"+str(len(google_index)))\n",
    "    # retrieve id for each set\n",
    "    amazon_id = (amazon_data[\"idAmazon\"][amazon_index]).tolist()\n",
    "    google_id = (google_data[\"idGoogle\"][google_index]).tolist()\n",
    "    # calculate the similarity for each pair\n",
    "    similarity = []\n",
    "    for i in range(0,len(amazon_index)):\n",
    "         similarity.append(round(similarity_matrix[amazon_index[i]][google_index[i]],2))\n",
    "    # potential candidate\n",
    "    potential_pairs = pd.DataFrame({\"idAmazon\":amazon_id,\"idGoogle\":google_id,\"similarity\":similarity})\n",
    "    return potential_pairs\n",
    "\n",
    "# Generate the labels\n",
    "def negatives_generator(perfect_matching,potential_matching):\n",
    "    # check the quality of blcoking\n",
    "    auxiliary = pd.merge(perfect_matching,potential_matching, on=[\"idAmazon\",\"idGoogle\"], how=\"outer\", indicator=True)\n",
    "    print(\"true positve/recall: \"+str(len(*np.where(auxiliary[\"_merge\"]==\"both\"))))\n",
    "    print(\"false positive/- samples: \"+str(len(*np.where(auxiliary[\"_merge\"]==\"right_only\"))))\n",
    "    print(\"false negative/+ lost: \"+str(len(*np.where(auxiliary[\"_merge\"]==\"left_only\")))+\"\\n\")\n",
    "    # labelling\n",
    "    auxiliary[\"label\"] = np.where(auxiliary[\"_merge\"]==\"both\",1,0) \n",
    "    print(\"No. of positives: \"+str(len(*np.where(auxiliary[\"label\"]==1))))\n",
    "    print(\"No. of negatives: \"+str(len(*np.where(auxiliary[\"label\"]==0)))+\"\\n\")\n",
    "    auxiliary = auxiliary[[\"similarity\",\"idAmazon\",\"idGoogle\",\"label\"]]\n",
    "    auxiliary['similarity'].fillna(1,inplace=True) \n",
    "    return auxiliary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity matrix for training sets\n",
    "train_cos_sim = similarity_matrix_generator(amazon_train[\"name\"],google_train[\"name\"])\n",
    "# cosine similarity matrix for testing sets\n",
    "test_cos_sim = similarity_matrix_generator(amazon_test[\"name\"],google_test[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1113, 2588)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cos_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of amazon index: 3833\n",
      "length of google index: 3833\n",
      "No. of potential pairs in training set: 3833\n",
      "length of amazon index: 325\n",
      "length of google index: 325\n",
      "No. of potential pairs in testing set: 325\n"
     ]
    }
   ],
   "source": [
    "# potential candidates for training sets\n",
    "train_potential_matching = potential_matching(amazon_train,google_train,train_cos_sim,0.5)\n",
    "print(\"No. of potential pairs in training set: \"+str(len(train_potential_matching)))\n",
    "# potential candidates for testing sets\n",
    "test_potential_matching = potential_matching(amazon_test,google_test,test_cos_sim,0.5)\n",
    "print(\"No. of potential pairs in testing set: \"+str(len(test_potential_matching)))\n",
    "# [idAmazon, idGoogle, similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positve/recall: 806\n",
      "false positive/- samples: 3027\n",
      "false negative/+ lost: 260\n",
      "\n",
      "No. of positives: 806\n",
      "No. of negatives: 3287\n",
      "\n",
      "true positve/recall: 173\n",
      "false positive/- samples: 152\n",
      "false negative/+ lost: 61\n",
      "\n",
      "No. of positives: 173\n",
      "No. of negatives: 213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Label\n",
    "train_index_labels = negatives_generator(train_perfect_matching,train_potential_matching)\n",
    "# train_index_labels\n",
    "test_index_labels = negatives_generator(test_perfect_matching,test_potential_matching)\n",
    "#[similarity, idAmazon, idGoogle, label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold 0.1, 0.2, 0.3, 0.4, 0.5\n",
    "total_pairs = len(amazon_train)*len(google_train)\n",
    "total_generated = np.array([170886,61589,18613,8387,3833])\n",
    "true_positive = np.array([1055,1043,999,945,806])\n",
    "false_positive = np.array([169831,60546,17614,7442,3027])\n",
    "false_negative = np.array([11,23,67,121,260])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction Rate\n",
    "reduction_rate = 1 - total_generated/total_pairs\n",
    "# Pair Completeness\n",
    "recall = true_positive/(true_positive+false_negative)\n",
    "# pairs quality\n",
    "precision = true_positive/total_generated\n",
    "# harmonic_mean\n",
    "f = recall*precision/(recall+precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of total pairs: 2880444\n",
      "Reduction Rate: [0.94067373 0.97861823 0.99353815 0.9970883  0.9986693 ]\n",
      "Pair Completeness: [0.98968105 0.97842402 0.93714822 0.88649156 0.75609756]\n",
      "Pairs Quality: [0.00617371 0.01693484 0.05367216 0.11267438 0.21027915]\n",
      "Harmonic Mean: [0.00613543 0.01664672 0.05076477 0.09996826 0.16452337]\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of total pairs: \"+str(total_pairs))\n",
    "print(\"Reduction Rate: \"+str(reduction_rate))\n",
    "print(\"Pair Completeness: \"+str(recall))\n",
    "print(\"Pairs Quality: \"+str(precision))\n",
    "print(\"Harmonic Mean: \"+str(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>reduction_rate</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>harmonic_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.940674</td>\n",
       "      <td>0.989681</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>0.006135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.978618</td>\n",
       "      <td>0.978424</td>\n",
       "      <td>0.016935</td>\n",
       "      <td>0.016647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.993538</td>\n",
       "      <td>0.937148</td>\n",
       "      <td>0.053672</td>\n",
       "      <td>0.050765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.997088</td>\n",
       "      <td>0.886492</td>\n",
       "      <td>0.112674</td>\n",
       "      <td>0.099968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.998669</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.210279</td>\n",
       "      <td>0.164523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  reduction_rate    recall  precision  harmonic_mean\n",
       "0        0.1        0.940674  0.989681   0.006174       0.006135\n",
       "1        0.2        0.978618  0.978424   0.016935       0.016647\n",
       "2        0.3        0.993538  0.937148   0.053672       0.050765\n",
       "3        0.4        0.997088  0.886492   0.112674       0.099968\n",
       "4        0.5        0.998669  0.756098   0.210279       0.164523"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = [0.1,0.2,0.3,0.4,0.5]\n",
    "cosine_analysis = pd.DataFrame({\"threshold\":threshold, \"reduction_rate\":reduction_rate,\"recall\":recall,\"precision\":precision,\"harmonic_mean\":f})\n",
    "cosine_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_analysis.to_csv(\"cosine_analysis.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
